{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5070163f-6b45-4f94-9890-3a2e4ba33490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import random\n",
    "import tarfile\n",
    "import os.path\n",
    "import json\n",
    "import pickle\n",
    "import ast\n",
    "import copy\n",
    "import re\n",
    "import string\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import datetime as dt\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # Turn off the SettingWithCopyWarning\n",
    "tqdm.pandas()\n",
    "# NLP\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import bigrams, trigrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "from datasets import load_dataset, load_metric, Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, f1_score, accuracy_score, RocCurveDisplay\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForTokenClassification, TokenClassificationPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2133172b-327d-4e1e-a5b1-2b4b2440d41a",
   "metadata": {},
   "source": [
    "#### Train Test DF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a0f00aa2-a608-4c31-8ed4-b810bebbd6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Action</th>\n",
       "      <th>Action_number</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test your mental toughness. Staffin turned it ...</td>\n",
       "      <td>No action</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So far tonight champeney one of five for just ...</td>\n",
       "      <td>No action</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Texas Tech is gonna stay unbeaten at home. Ohh...</td>\n",
       "      <td>No action</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crosswell inside over Wheeler it goes. Good move.</td>\n",
       "      <td>No action</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virginia is kind of used to playing log in the...</td>\n",
       "      <td>No action</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Action  \\\n",
       "0  Test your mental toughness. Staffin turned it ...  No action   \n",
       "1  So far tonight champeney one of five for just ...  No action   \n",
       "2  Texas Tech is gonna stay unbeaten at home. Ohh...  No action   \n",
       "3  Crosswell inside over Wheeler it goes. Good move.  No action   \n",
       "4  Virginia is kind of used to playing log in the...  No action   \n",
       "\n",
       "   Action_number  Label  \n",
       "0              0      0  \n",
       "1              0      0  \n",
       "2              0      0  \n",
       "3              0      0  \n",
       "4              0      0  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_enrichment_df_train = pd.read_csv(\"/sise/home/ofirbenm/Wsc_ex1/action_enrichment_df_train.csv\")\n",
    "action_enrichment_df_test = pd.read_csv(\"/sise/home/ofirbenm/Wsc_ex1/action_enrichment_df_test.csv\")\n",
    "actions_number = action_enrichment_df_train.Action.nunique()\n",
    "action_enrichment_df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc653e4-b101-4e02-b2b0-7bcb550a8f69",
   "metadata": {},
   "source": [
    "#### Action to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c89a86cd-b065-4d0b-8180-e1f7f8ac8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/sise/home/ofirbenm/Wsc_ex1/action_enrichment_ds_home_exercise_old.csv\"\n",
    "action_enrichment_df = pd.read_csv(file_path)\n",
    "actions = action_enrichment_df.Action.unique()\n",
    "number_to_action = {i:action for i, action in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9fcd50-1f51-4071-b0db-c56baa1acbbf",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c533d06-ec2d-4e25-85a5-87856fefface",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "bert_model = \"bert-base-uncased\"\n",
    "\n",
    "action_model_path = \"/sise/home/ofirbenm/Wsc_ex1/bert_action_model.pth\"\n",
    "action_model = BertForSequenceClassification.from_pretrained(bert_model, num_labels=actions_number)\n",
    "action_model.load_state_dict(torch.load(action_model_path))\n",
    "action_model.to(device)\n",
    "action_model.eval()\n",
    "\n",
    "validity_model_path = \"/sise/home/ofirbenm/Wsc_ex1/bert_validity_model.pth\"\n",
    "validity_model = BertForSequenceClassification.from_pretrained(bert_model, num_labels=2)\n",
    "validity_model.load_state_dict(torch.load(validity_model_path))\n",
    "validity_model.to(device)\n",
    "validity_model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_model)\n",
    "opt_thresh_model = 0.392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c35d0472-651d-4443-91f5-23dc30d85bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_action(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "    inputs.to(device)\n",
    "    outputs = action_model(**inputs)\n",
    "    predicted_label = torch.argmax(outputs.logits).item()\n",
    "    return predicted_label\n",
    "\n",
    "def predict_label(text, action):\n",
    "    inputs = tokenizer(text, action, padding=\"max_length\", add_special_tokens=True, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    logits = validity_model(**inputs).logits\n",
    "    return F.softmax(logits, dim=1).tolist()[0]\n",
    "\n",
    "def predict(text):\n",
    "    action_number = predict_action(text)\n",
    "    action = number_to_action[action_number]\n",
    "    if action_number == 0:\n",
    "        print(f'There is no action in the  transcript.')\n",
    "        label = 0\n",
    "        return action, label\n",
    "    else:\n",
    "        softmax = predict_label(row['Text'], action)\n",
    "        label = 1 if softmax[1] > opt_thresh_model else 0\n",
    "        if label == 1:\n",
    "            print(f\"The action is '{action}'.\")\n",
    "        else:\n",
    "            print(f\"The action '{action}' is not valid.\")\n",
    "        return action, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "aa1bdbc2-7f7e-4293-bcd8-25d70a376532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test set: 86.076%\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "for i, row in tqdm(action_enrichment_df_test.iterrows(), total=len(action_enrichment_df_test)):\n",
    "    action, label = predict(row['Text'])\n",
    "    if action == row['Action'] and label == row['Label']:\n",
    "        correct_predictions += 1\n",
    "\n",
    "total_predictions = action_enrichment_df_test.shape[0]\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(\"Accuracy on Test set: {:.3f}%\".format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“Bert_politics”",
   "language": "python",
   "name": "bert_politics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
